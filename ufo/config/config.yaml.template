version: 0.1

API_TYPE: "openai" # The API type, "openai" for the OpenAI API, "aoai" for the AOAI API, 'azure_ad' for the ad authority of the AOAI API.
OPENAI_API_BASE: "YOUR_ENDPOINT" # The OpenAI API.
OPENAI_API_KEY: "YOUR_API_KEY"  # The OpenAI API key
AOAI_DEPLOYMENT: "YOUR_AOAI_DEPLOYMENT"  # Your AOAI deployment if apply
API_VERSION: "2024-02-15-preview" # For GPT4-visual, the value usually be the "2023-12-01-preview"
OPENAI_API_MODEL: "gpt-4-vision-preview"  # The only OpenAI model by now that accepts visual input

CONTROL_BACKEND: "uia"  # The backend for control action
MAX_TOKENS: 2000  # The max token limit for the response completion
MAX_RETRY: 3  # The max retry limit for the response completion
MAX_STEP: 30  # The max step limit for completing the user request
SLEEP_TIME: 5  # The sleep time between each step to wait for the window to be ready
TEMPERATURE: 0.0  # The temperature of the model: the lower the value, the more consistent the output of the model
TOP_P: 0.0  # The top_p of the model: the lower the value, the more conservative the output of the model
SAFE_GUARD: True  # Whether to use the safe guard to prevent the model from doing sensitve operations.
CONTROL_TYPE_LIST: ["Button", "Edit", "TabItem", "Document", "ListItem", "MenuItem", "ScrollBar", "TreeItem", "Hyperlink", "ComboBox", "RadioButton"]  # The list of control types that are allowed to be selected 
HISTORY_KEYS: ["Step", "Thought", "ControlText", "Action", "Comment", "Results"]  # The keys of the action history for the next step.
ANNOTATION_COLORS: {
        "Button": "#FFF68F",
        "Edit": "#A5F0B5",
        "TabItem": "#A5E7F0",
        "Document": "#FFD18A",
        "ListItem": "#D9C3FE",
        "MenuItem": "#E7FEC3",
        "ScrollBar": "#FEC3F8",
        "TreeItem": "#D6D6D6",
        "Hyperlink": "#91FFEB",
        "ComboBox": "#D8B6D4"
    }

PRINT_LOG: False  # Whether to print the log  
CONCAT_SCREENSHOT: True  # Whether to concat the screenshot for the control item
LOG_LEVEL: "DEBUG"  # The log level
INCLUDE_LAST_SCREENSHOT: True  # Whether to include the last screenshot in the observation
REQUEST_TIMEOUT: 250  # The call timeout for the GPT-V model
APP_SELECTION_PROMPT: "ufo/prompts/base/app_selection.yaml"  # The prompt for the app selection
ACTION_SELECTION_PROMPT: "ufo/prompts/base/action_selection.yaml"  # The prompt for the action selection
INPUT_TEXT_API: "type_keys" # The input text API

### For AAD
AAD_TENANT_ID: "YOUR_TENANT_ID" # Set the value to your tenant id for the llm model
AAD_API_SCOPE: "YOUR_SCOPE" # Set the value to your scope for the llm model
AAD_API_SCOPE_BASE: "YOUR_SCOPE_BASE" # Set the value to your scope base for the llm model, whose format is API://YOUR_SCOPE_BASE

APP_AGENT_VISUAL_MODE: True  # Whether to use the visual mode for the app agent
ACTION_AGENT_VISUAL_MODE: True  # Whether to use the visual mode for the action agent
OPENAI_API_BASE_NON_VISUAL: "YOUR_NON_VISUAL_ENDPOINT"  # The OpenAI endpoint for non-visual model
OPENAI_API_KEY_NON_VISUAL: "YOUR_API_KEY"  # The OpenAI API key for non-visual model
OPENAI_API_MODEL_NON_VISUAL: "gpt-4-1106-preview"  # The non-visual OpenAI model
APP_SELECTION_NON_VISUAL_PROMPT: "ufo/prompts/nonvisual/app_selection.yaml"  # The non-visual prompt for the app selection
ACTION_SELECTION_NON_VISUAL_PROMPT: "ufo/prompts/nonvisual/action_selection.yaml"  # The non-visual prompt for the action selection
